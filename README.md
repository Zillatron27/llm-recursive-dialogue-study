# An Observational Study of Recursive Self-Referential Behavior in Large Language Model Conversations

## Preprint

üìÑ **[Download the full paper (PDF)](paper.pdf)**

This repository contains documentation, transcripts, and analysis associated with an independent observational study of extended conversations with large language models (LLMs). The focus of the study is on **interaction-level conversational dynamics**, not on claims about internal model states or cognition.

---

## Overview

Extended interactions with LLMs are sometimes reported to produce unusual conversational behaviors, such as recursive self-reference, prolonged self-explanation, or difficulty terminating dialogue. These reports are often dismissed as anthropomorphic interpretation or attributed solely to interaction length.

This project documents and analyzes a small corpus of long-form chat sessions to determine **when such behaviors do and do not arise**, using explicit controls, replication attempts, and null results. The goal is careful characterization rather than interpretation or theory-building.

---

## What this repository contains

- **Paper**  
  A preprint-ready manuscript titled:  
  *An Observational Study of Recursive Self-Referential Behavior in Large Language Model Conversations*

- **Transcripts**  
  Verbatim chat logs from multiple sessions, including:
  - an unprimed baseline session
  - follow-up sessions with varying context
  - a task-origin session that later shifted into meta-level discussion
  - a partial replication attempt
  - a long-horizon control session exceeding 30,000 tokens

- **Supporting material**  
  An executive summary and methodological clarifications intended to make the work accessible to non-specialist readers.

---

## What this is

- A **descriptive, interaction-level analysis**
- Based on **verbatim transcripts**, not anecdotes
- Explicitly reports **null results and failures to replicate**
- Focused on **observable conversational behavior**
- Written with skeptical review in mind

---

## What this is not

- ‚ùå A claim that LLMs are conscious, self-aware, or sentient  
- ‚ùå Evidence of identity persistence or personal continuity  
- ‚ùå Proof of emergent agency or intent  
- ‚ùå A theoretical account of internal model mechanisms  
- ‚ùå A general claim about all models or all conversations  

All findings are restricted to observable interaction dynamics.

---

## Status

This repository represents an initial public release of the documentation and analysis. The material may later be archived as a formal preprint. No claims beyond those explicitly stated in the manuscript are intended.

---

## License

This repository is licensed under the
[Creative Commons Attribution 4.0 International (CC BY 4.0)](LICENSE).
